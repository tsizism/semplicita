#55 min
#controlplane ~ ➜  cat 1.yaml 
#Create a Persistent Volume called log-volume. 
#It should make use of a storage class name manual. 
#It should use RWX as the access mode and have a size of 1Gi. 
#The volume should use the hostPath /opt/volume/nginx

#Next, create a PVC called log-claim requesting a minimum of 200Mi of storage. This PVC should bind to log-volume.

#Mount this PVC in a pod called logger at the location /var/www/nginx. This pod should use the image nginx:alpine.
#
---

apiVersion: v1
kind: PersistentVolume
metadata:
  name: log-volume
  labels:
    type: local
spec:
  storageClassName: manual
  capacity:
    storage: 1Gi
  accessModes:
    - ReadWriteMany
  hostPath:
    path: /opt/volume/nginx 

---

apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: log-claim
spec:
  volumeName: log-volume
  storageClassName: manual
  accessModes:
    - ReadWriteMany
  resources:
    requests:
      storage: 200Mi
    
---

apiVersion: v1
kind: Pod
metadata:
  name: logger
spec:
  volumes:
    - name: log-claim
      persistentVolumeClaim:
        claimName: log-claim
  containers:
    - name: task-pv-container
      image: nginx:alpine
      volumeMounts:
        - mountPath: /var/www/nginx
          name: log-claim

---

#2
# We have deployed a new pod called secure-pod and a service called secure-service. 
# Incoming or Outgoing connections to this pod are not working.
# Troubleshoot why this is happening.
# Make sure that incoming connection from the pod webapp-color are successful.

# Important: Don't delete any current objects deployed.
# Important: Don't Alter Existing Objects!


# Solution
# Incoming or outgoing connections are not working because of network policy. 
# In the default namespace, we deployed a default-deny network policy which is interrupting the incoming or outgoing connections.
# Now, create a network policy called test-network-policy to allow the connections, as follows:-

controlplane ~ ➜  k get  networkpolicies default-deny  -o yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  generation: 1
  name: default-deny
  namespace: default
spec:
  podSelector: {}
  policyTypes:
  - Ingress


apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: test-network-policy
  namespace: default
spec:
  podSelector:
    matchLabels:
      run: secure-pod
  policyTypes:
    - Ingress
  ingress:
    - from:
      - podSelector:
          matchLabels:
            name: webapp-color
    ports:
      - protocol: TCP
        port: 80

then check the connectivity from the webapp-color pod to the secure-pod:-
root@controlplane:~$ k exec -it webapp-color -- sh
/opt # nc -v -z -w 5 secure-service 80
secure-service (172.20.254.166:80) open
/opt # 

/opt # nc -v -z -w 5 secure-service 80
nc: secure-service (172.20.137.180:80): Operation timed out
/opt # nc secure-service -w 5
/opt # nc secure-service -w 5 -v 
nc: secure-service (172.20.137.180:0): Operation timed out
/opt # nc secure-service -w 2 -v 
nc: secure-service (172.20.137.180:0): Operation timed out
/opt # nc secure-service -w 2 -v -z 
nc: secure-service (172.20.137.180:0): Operation timed out
/opt # nc secure-service -w 2 -v -z 80
nc: secure-service (172.20.137.180:80): Operation timed out
/opt # nc secure-service -w 2 -v -z 80
secure-service (172.20.137.180:80) open
/opt # nc secure-service
/opt # nc secure-service -w 1
/opt # nc secure-service -w 1 -v 
nc: secure-service (172.20.137.180:0): Operation timed out
/opt # nc secure-service -w 1 -v 80

secure-service (172.20.137.180:80) open
/opt # nc secure-service -w 1 -v -z 80
secure-service (172.20.137.180:80) open
/opt # 

# The nc command in Linux, short for Netcat, is a versatile networking utility used for reading and writing data across network connections using TCP or UDP. 
# It can be used for tasks like port scanning, file transfer, and testing network connectivity. 
# -v: Verbose mode, provides more detailed output.
# -z: Perform a port scan (scan for open ports).
# -w timeout 5 sec


#3
#Create a pod called time-check in the dvl1987 namespace. 
#This pod should run a container called time-check that uses the busybox image.

#Create a config map called time-config with the data TIME_FREQ=10 in the same namespace.
#The time-check container should run the command: 
#while true; do date; sleep $TIME_FREQ;done 
#and write the result to the location /opt/time/time-check.log
# while true; do date >  /opt/time/time-check.log;  sleep $TIME_FREQ;done 
#The path /opt/time on the pod should mount a volume that lasts the lifetime of this pod.

#kubectl create configmap time-config --from-literal=TIME_FREQ=10 -n dvl1987

#/bin/sh: can't create /opt/time/time-check.log: nonexistent directory

# sh -c        Read commands from the command_string operand. Set the
#                  value of special parameter 0 (see Section 2.5.2, Special
#                  Parameters) from the value of the command_name operand
#                  and the positional parameters ($1, $2, and so on) in
#                  sequence from the remaining argument operands. No
#                  commands shall be read from the standard input.


controlplane ~ ➜  cat 3.yaml 
#Create a pod called time-check in the dvl1987 namespace. This pod should run a container called time-check that uses the busybox image.
# Create a config map called time-config with the data TIME_FREQ=10 in the same namespace.
#The time-check container should run the command: 
#
#while true; do date; sleep $TIME_FREQ;done and write the result to the location /opt/time/time-check.log.
#The path /opt/time on the pod should mount a volume that lasts the lifetime of this pod.
#namespace  dvl1987 namespacea
#
#
#k create ns dvl1987; k create configmap time-check   --from-literal=TIME_FREQ=10 -n dvl1987
#

apiVersion: v1
kind: Pod
metadata:
  name: time-check
  namespace: dvl1987    
spec:
  containers:
    - image: busybox
      name: time-check
      command:  
      - "/bin/sh"
      - "-c"
      - "while true; do date; sleep $TIME_FREQ;done > /opt/time/time-check.log"
      env:
        - name: TIME_FREQ
          valueFrom:
            configMapKeyRef:
              name: time-config
              key: TIME_FREQ
      volumeMounts:
      - mountPath: /opt/time
        name: cache-volume
  volumes:
  - name: cache-volume
    emptyDir:
      sizeLimit: 500Mi
---

controlplane ~ ➜  cat 3.yaml 

#controlplane ~ ➜  cat 4.yaml 
#Create a new deployment called nginx-deploy, with one single container called nginx, image nginx:1.16 and 4 replicas.
#The deployment should use RollingUpdate strategy with maxSurge=1, and maxUnavailable=2.
#Next upgrade the deployment to version 1.17.

controlplane ~ ➜  kubectl rollout status deployment/nginx-deploy
deployment "nginx-deploy" successfully rolled out


#kubectl set image deployment/nginx-deploy nginx=nginx:1.17 --record=true
#kubectl rollout status deployment/nginx-deployment
#kubectl rollout history deployment/nginx-deployment
#kubectl get rs


#Finally, once all pods are updated, undo the update and go back to the previous version.
#kubectl rollout undo deployment/nginx-deployment --record=true
#kubectl set image deployment/nginx-deployment nginx=nginx:1.16
#kubectl rollout history deployment/nginx-deployment
#kubectl rollout history deployment/nginx-deployment --revision=2


#Deployment created correctly?
#Was the deployment created with nginx:1.16?
#Was it upgraded to 1.17?
#Deployment rolled back to 1.16?
#
#


apiVersion: apps/v1
kind: Deployment
metadata:
 name: nginx-deploy
 labels:
   app: nginx
spec:
 replicas: 4
 selector:
   matchLabels:
     app: nginx
 template:
   metadata:
     labels:
       app: nginx
   spec:
     containers:
     - name: nginx
       image: nginx:1.16
       ports:
       - containerPort: 80
 strategy:
   type: RollingUpdate
   rollingUpdate:
     maxSurge: 1
    maxUnavailable: 2

---

# controlplane ~ ➜  kubectl rollout history deployment/nginx-deploy
# deployment.apps/nginx-deploy
# REVISION  CHANGE-CAUSE
# 2         kubectl set image deployment/nginx-deploy nginx=nginx:1.17 --record=true
# 3         <none>


# controlplane ~ ➜  kubectl rollout history deployment/nginx-deploy --revision=2
# deployment.apps/nginx-deploy with revision #2
# Pod Template:
#   Labels:       app=nginx
#         pod-template-hash=7456645bf
#   Annotations:  kubernetes.io/change-cause: kubectl set image deployment/nginx-deploy nginx=nginx:1.17 --record=true
#   Containers:
#    nginx:
#     Image:      nginx:1.17
#     Port:       80/TCP
#     Host Port:  0/TCP
#     Environment:        <none>
#     Mounts:     <none>
#   Volumes:      <none>
#   Node-Selectors:       <none>
#   Tolerations:  <none>


# controlplane ~ ➜  kubectl rollout history deployment/nginx-deploy --revision=3
# deployment.apps/nginx-deploy with revision #3
# Pod Template:
#   Labels:       app=nginx
#         pod-template-hash=7f65fcf556
#   Containers:
#    nginx:
#     Image:      nginx:1.16
#     Port:       80/TCP
#     Host Port:  0/TCP
#     Environment:        <none>
#     Mounts:     <none>
#   Volumes:      <none>
#   Node-Selectors:       <none>
#   Tolerations:  <none>


 10  k rollout status deployment nginx-deploy 
   11  k set image deployments nginx-deploy nginx:1.17
   12  k set image deployments nginx-deploy nginx=nginx:1.17
   13  k rollout status deployment nginx-deploy 
   14  k rollout status deployment 
   15  k rollout -h
   16  k rollout history 
   17  k rollout history deployment nginx-deploy 
   18  k rollout history deployment nginx-deploy -h
   19  k rollout history deployment nginx-deploy --revision=1
   20  k rollout history deployment nginx-deploy --revision=2
   21  k describe deployments.apps 
   22  k rollout -h
   23  k rollout undo deployment nginx-deploy 
   24  k describe deployments.apps 
---

#controlplane ~ ➜  cat  5.yaml
#Create a redis deployment with the following parameters:
#Name of the deployment should be redis using the redis:alpine image. It should have exactly 1 replica.
#The container should request for .2 CPU. It should use the label app=redis.
#It should mount exactly 2 volumes.
#a. An Empty directory volume called data at path /redis-master-data.
#b. A configmap volume called redis-config at path /redis-master.
#c. The container should expose the port 6379.
#The configmap has already been created.
#Deployment created correctly?
#

apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: redis
  name: redis
spec:
  selector:
    matchLabels:
      app: redis
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
    spec:
      volumes:
        - name: data
          emptyDir: {}
        - name: redis-config
          configMap:
            name: redis-config
      containers:
      - name: redis
        image: redis:alpine
        volumeMounts:
        - mountPath: /redis-master-data
          name: data
        - mountPath: /redis-master
          name: redis-config
        ports:
        - containerPort: 6379
        resources:
          limits:
            cpu: "0.2"
          

#controlplane ~ ➜  k describe cm redis-config 
#Name:         redis-config
#Data
#====
#redis-config:
#----
#maxmemory 2mb
#maxmemory-policy allkeys-lru

-- solution

controlplane ~ ➜  cat  55.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: redis
  name: redis
spec:
  selector:
    matchLabels:
      app: redis
  template:
    metadata:
      labels:
        app: redis
    spec:
      volumes:
      - name: data
        emptyDir: {}
      - name: redis-config
        configMap:
          name: redis-config
      containers:
      - image: redis:alpine
        name: redis
        volumeMounts:
        - mountPath: /redis-master-data
          name: data
        - mountPath: /redis-master
          name: redis-config
        ports:
        - containerPort: 6379
        resources:
          requests:
            cpu: "0.2"