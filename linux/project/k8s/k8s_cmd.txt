Certification Tip: Imperative Commands

While you would be working mostly the declarative way - using definition files, 
imperative commands can help in getting one-time tasks done quickly, 
as well as generate a definition template easily. 
This would help save a considerable amount of time during your exams.

Before we begin, familiarize yourself with the two options that can come in handy while working with the below commands:

--dry-run: By default, as soon as the command is run, the resource will be created. 
If you simply want to test your command, use the --dry-run=client option. This will not create the resource. Instead, tell you whether the resource can be created and if your command is right.

-o yaml: This will output the resource definition in YAML format on the screen.



Use the above two in combination along with Linux output redirection to generate a resource definition file quickly, that you can then modify and create resources as required, instead of creating the files from scratch.
kubectl run nginx --image=nginx --dry-run=client -o yaml > nginx-pod.yaml



POD
Create an NGINX Pod
kubectl run nginx --image=nginx


Generate POD Manifest YAML file (-o yaml). Don't create it(--dry-run)
kubectl run nginx --image=nginx --dry-run=client -o yaml



Deployment
Create a deployment

kubectl create deployment --image=nginx nginx


Generate Deployment YAML file (-o yaml). Don't create it(--dry-run)
kubectl create deployment --image=nginx nginx --dry-run -o yaml


Generate Deployment with 4 Replicas
kubectl create deployment nginx --image=nginx --replicas=4

You can also scale deployment using the kubectl scale command.
kubectl scale deployment nginx --replicas=4


Another way to do this is to save the YAML definition to a file and modify
kubectl create deployment nginx --image=nginx--dry-run=client -o yaml > nginx-deployment.yaml

You can then update the YAML file with the replicas or any other field before creating the deployment.

Service
Create a Service named redis-service of type ClusterIP to expose pod redis on port 6379

kubectl expose pod redis --port=6379 --name redis-service --dry-run=client -o yaml

(This will automatically use the pod's labels as selectors)
Or
kubectl create service clusterip redis --tcp=6379:6379 --dry-run=client -o yaml 
(This will not use the pods' labels as selectors; instead it will assume selectors as app=redis. 
You cannot pass in selectors as an option. So it does not work well if your pod has a different label set. 
So generate the file and modify the selectors before creating the service)


Create a Service named nginx of type NodePort to expose pod nginx's port 80 on port 30080 on the nodes:

kubectl expose pod nginx --port=80 --name nginx-service --type=NodePort --dry-run=client -o yaml

(This will automatically use the pod's labels as selectors, but you cannot specify the node port. You have to generate a definition file and then add the node port in manually before creating the service with the pod.)

Or

kubectl create service nodeport nginx --tcp=80:80 --node-port=30080 --dry-run=client -o yaml
(This will not use the pods' labels as selectors)

Both the above commands have their own challenges. While one of it cannot accept a selector the other cannot accept a node port. I would recommend going with the `kubectl expose` command. If you need to specify a node port, generate a definition file using the same command and manually input the nodeport before creating the service.


Reference:
https://kubernetes.io/docs/reference/kubectl/conventions/


Recommended usage conventions for kubectl.

Using kubectl in Reusable Scripts
For a stable output in a script:

Request one of the machine-oriented output forms, such as -o name, -o json, -o yaml, -o go-template, or -o jsonpath.

Fully-qualify the version. For example, jobs.v1.batch/myjob. This will ensure that kubectl does not use its default version that can change over time.

Don't rely on context, preferences, or other implicit states.

Subresources
You can use the --subresource beta flag for kubectl commands like get, patch, edit and replace to fetch and update subresources for all resources that support them. 
Currently, only the status and scale subresources are supported.
For kubectl edit, the scale subresource is not supported. If you use --subresource with kubectl edit and specify scale as the subresource, the command will error out.
The API contract against a subresource is identical to a full resource. 
While updating the status subresource to a new value, keep in mind that the subresource could be potentially reconciled by a controller to a different value.

Best Practices
kubectl run
For kubectl run to satisfy infrastructure as code:
* Tag the image with a version-specific tag and don't move that tag to a new version. 
For example, use :v1234, v1.2.3, r03062016-1-4, rather than :latest 
(For more information, see Best Practices for Configuration https://kubernetes.io/docs/concepts/configuration/overview/#container-images).
* Check in the script for an image that is heavily parameterized.
* Switch to configuration files checked into source control for features that are needed, but not expressible via kubectl run flags.
You can use the --dry-run=client flag to preview the object that would be sent to your cluster, without really submitting it.

kubectl apply
You can use kubectl apply to create or update resources. 
For more information about using kubectl apply to update resources, see Kubectl Book. 
https://kubectl.docs.kubernetes.io/